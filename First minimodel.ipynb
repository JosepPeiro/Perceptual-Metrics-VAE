{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jpeir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from preprocessing import Preprocessing, SplitAudio\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jpeir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ruta_carpeta = \"./MusicCaps\"  # Reemplaza con la ruta real de tu carpeta\n",
    "\n",
    "archivos = os.listdir(ruta_carpeta)\n",
    "\n",
    "X = []\n",
    "metadata = []\n",
    "sample_rate_red = 16000\n",
    "for archivo in archivos[:200]:\n",
    "    waveform, samp_rt = torchaudio.load(\"./MusicCaps/\" + archivo)\n",
    "    f, s = SplitAudio(waveform, sample_rate = samp_rt, new_sample_rate = sample_rate_red)\n",
    "\n",
    "    f_spec, f_maxi, f_mini = Preprocessing(f, 16000, resampler_f = False)\n",
    "    s_spec, s_maxi, s_mini = Preprocessing(s, 16000, resampler_f = False)\n",
    "\n",
    "    X += [f_spec, s_spec]\n",
    "    metadata += [{\"nombre\":archivo, \"parte\":\"first\", \"minimum\":f_mini, \"maximum\":f_maxi},\n",
    "                 {\"nombre\":archivo, \"parte\":\"second\", \"minimum\":s_mini, \"maximum\":s_maxi}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 256, 256])\n",
      "torch.Size([400, 1, 256, 256])\n",
      "Batch shape: torch.Size([64, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convertir la lista de espectrogramas en un tensor\n",
    "X_tensor = torch.stack(X)  # Suponiendo que X es una lista de tensores (N, 256, 256)\n",
    "print(X_tensor.shape)\n",
    "# Añadir la dimensión del canal (1 para monocanal)\n",
    "X_tensor = X_tensor.unsqueeze(1)  # (N, 1, 256, 256)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "batch_size = 64\n",
    "dataset = TensorDataset(X_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    batch = batch[0]  # Extraer el tensor del DataLoader\n",
    "    print(\"Batch shape:\", batch.shape)  # Debe ser (64, 1, 256, 256)\n",
    "    break  # Solo mostramos el primer batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, stride=2, padding=1),  # Reduce tamaño a 128x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1),  # Reduce tamaño a 128x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "# Función de pérdida (MSE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizador AdamW\n",
    "optimizer = optim.AdamW(autoencoder.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Autoencoder                              [64, 1, 256, 256]         --\n",
       "├─Sequential: 1-1                        [64, 128, 16, 16]         --\n",
       "│    └─Conv2d: 2-1                       [64, 128, 128, 128]       1,280\n",
       "│    └─BatchNorm2d: 2-2                  [64, 128, 128, 128]       256\n",
       "│    └─LeakyReLU: 2-3                    [64, 128, 128, 128]       --\n",
       "│    └─Conv2d: 2-4                       [64, 128, 64, 64]         147,584\n",
       "│    └─BatchNorm2d: 2-5                  [64, 128, 64, 64]         256\n",
       "│    └─LeakyReLU: 2-6                    [64, 128, 64, 64]         --\n",
       "│    └─Conv2d: 2-7                       [64, 128, 32, 32]         147,584\n",
       "│    └─BatchNorm2d: 2-8                  [64, 128, 32, 32]         256\n",
       "│    └─LeakyReLU: 2-9                    [64, 128, 32, 32]         --\n",
       "│    └─Conv2d: 2-10                      [64, 128, 16, 16]         147,584\n",
       "│    └─BatchNorm2d: 2-11                 [64, 128, 16, 16]         256\n",
       "│    └─Tanh: 2-12                        [64, 128, 16, 16]         --\n",
       "├─Sequential: 1-2                        [64, 1, 256, 256]         --\n",
       "│    └─ConvTranspose2d: 2-13             [64, 128, 32, 32]         147,584\n",
       "│    └─BatchNorm2d: 2-14                 [64, 128, 32, 32]         256\n",
       "│    └─LeakyReLU: 2-15                   [64, 128, 32, 32]         --\n",
       "│    └─ConvTranspose2d: 2-16             [64, 128, 64, 64]         147,584\n",
       "│    └─BatchNorm2d: 2-17                 [64, 128, 64, 64]         256\n",
       "│    └─LeakyReLU: 2-18                   [64, 128, 64, 64]         --\n",
       "│    └─ConvTranspose2d: 2-19             [64, 128, 128, 128]       147,584\n",
       "│    └─BatchNorm2d: 2-20                 [64, 128, 128, 128]       256\n",
       "│    └─LeakyReLU: 2-21                   [64, 128, 128, 128]       --\n",
       "│    └─ConvTranspose2d: 2-22             [64, 128, 256, 256]       147,584\n",
       "│    └─BatchNorm2d: 2-23                 [64, 128, 256, 256]       256\n",
       "│    └─LeakyReLU: 2-24                   [64, 128, 256, 256]       --\n",
       "│    └─Conv2d: 2-25                      [64, 1, 256, 256]         1,153\n",
       "│    └─Sigmoid: 2-26                     [64, 1, 256, 256]         --\n",
       "==========================================================================================\n",
       "Total params: 1,037,569\n",
       "Trainable params: 1,037,569\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 879.08\n",
       "==========================================================================================\n",
       "Input size (MB): 16.78\n",
       "Forward/backward pass size (MB): 14294.19\n",
       "Params size (MB): 4.15\n",
       "Estimated Total Size (MB): 14315.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(autoencoder, input_size=(64, 1, 256, 256))  # (batch_size, channels, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de la salida: torch.Size([1, 128, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Autoencoder                              [64, 128, 64, 64]         --\n",
       "├─Sequential: 1-1                        [64, 128, 64, 64]         --\n",
       "│    └─Conv2d: 2-1                       [64, 128, 128, 128]       1,280\n",
       "│    └─BatchNorm2d: 2-2                  [64, 128, 128, 128]       256\n",
       "│    └─LeakyReLU: 2-3                    [64, 128, 128, 128]       --\n",
       "│    └─Conv2d: 2-4                       [64, 128, 64, 64]         147,584\n",
       "├─Sequential: 1-2                        [64, 128, 64, 64]         --\n",
       "│    └─LeakyReLU: 2-5                    [64, 128, 64, 64]         --\n",
       "==========================================================================================\n",
       "Total params: 149,120\n",
       "Trainable params: 149,120\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 40.03\n",
       "==========================================================================================\n",
       "Input size (MB): 16.78\n",
       "Forward/backward pass size (MB): 2415.92\n",
       "Params size (MB): 0.60\n",
       "Estimated Total Size (MB): 2433.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, stride=2, padding=1),  # Reduce tamaño a 128x128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(in_channels=128, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            # nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Crear el modelo y verificar la forma de salida\n",
    "autoencoder = Autoencoder()\n",
    "x = torch.randn(1, 1, 256, 256)  # Ejemplo de entrada (batch=1, channels=1, height=256, width=256)\n",
    "output = autoencoder(x)\n",
    "print(\"Shape de la salida:\", output.shape)  # Debería ser (1, 1, 256, 256)\n",
    "summary(autoencoder, input_size=(64, 1, 256, 256))  # (batch_size, channels, height, width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
