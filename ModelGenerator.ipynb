{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jpeir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from LoadingDefault import LoadData, LoadNoise\n",
    "from AutoEncoderObjects import EntropyLimitedAutoencoder, MSSSIMLoss, NLPDLoss\n",
    "from torch.nn import MSELoss\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = LoadData(limit=30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida: 0.028757\n",
      "Pérdida: 0.083316\n",
      "Pérdida: 0.035745\n",
      "Pérdida: 0.027661\n",
      "Pérdida: 0.027375\n",
      "Pérdida: 0.021267\n",
      "Pérdida: 0.027529\n",
      "Pérdida: 0.021777\n",
      "Época [1/3], Pérdida: 0.034178\n",
      "Pérdida: 0.020303\n",
      "Pérdida: 0.016434\n",
      "Pérdida: 0.016502\n",
      "Pérdida: 0.013578\n",
      "Pérdida: 0.017905\n",
      "Pérdida: 0.020712\n",
      "Pérdida: 0.015434\n",
      "Pérdida: 0.012726\n",
      "Época [2/3], Pérdida: 0.016699\n",
      "Pérdida: 0.013049\n",
      "Pérdida: 0.011964\n",
      "Pérdida: 0.012080\n",
      "Pérdida: 0.012615\n",
      "Pérdida: 0.012666\n",
      "Pérdida: 0.012134\n",
      "Pérdida: 0.009976\n",
      "Pérdida: 0.011479\n",
      "Época [3/3], Pérdida: 0.011995\n",
      "Cambiando de modelo!!!!\n",
      "Pérdida: 587.453247\n",
      "Pérdida: 594.372864\n",
      "Pérdida: 484.347473\n",
      "Pérdida: 443.467072\n",
      "Pérdida: 407.119019\n",
      "Pérdida: 414.022095\n",
      "Pérdida: 413.993500\n",
      "Pérdida: 125.663834\n",
      "Época [1/3], Pérdida: 433.804888\n",
      "Pérdida: 405.950073\n",
      "Pérdida: 399.884369\n",
      "Pérdida: 367.167572\n",
      "Pérdida: 379.351135\n",
      "Pérdida: 350.089203\n",
      "Pérdida: 345.799347\n",
      "Pérdida: 338.748840\n",
      "Pérdida: 105.159821\n",
      "Época [2/3], Pérdida: 336.518795\n",
      "Pérdida: 358.447388\n",
      "Pérdida: 317.210266\n",
      "Pérdida: 339.915649\n",
      "Pérdida: 358.842529\n",
      "Pérdida: 331.204559\n",
      "Pérdida: 332.807831\n",
      "Pérdida: 326.105072\n",
      "Pérdida: 104.662048\n",
      "Época [3/3], Pérdida: 308.649418\n",
      "Cambiando de modelo!!!!\n",
      "Pérdida: 0.787703\n",
      "Pérdida: 0.797949\n",
      "Pérdida: 0.520803\n",
      "Pérdida: 0.454388\n",
      "Pérdida: 0.431941\n",
      "Pérdida: 0.365403\n",
      "Pérdida: 0.327264\n",
      "Pérdida: 0.347929\n",
      "Época [1/3], Pérdida: 0.504172\n",
      "Pérdida: 0.286496\n",
      "Pérdida: 0.280425\n",
      "Pérdida: 0.247041\n",
      "Pérdida: 0.243498\n",
      "Pérdida: 0.247520\n",
      "Pérdida: 0.216679\n",
      "Pérdida: 0.210566\n",
      "Pérdida: 0.221985\n",
      "Época [2/3], Pérdida: 0.244276\n",
      "Pérdida: 0.220475\n",
      "Pérdida: 0.186799\n",
      "Pérdida: 0.213943\n",
      "Pérdida: 0.206352\n",
      "Pérdida: 0.191950\n",
      "Pérdida: 0.189206\n",
      "Pérdida: 0.177660\n",
      "Pérdida: 0.170747\n",
      "Época [3/3], Pérdida: 0.194641\n",
      "Cambiando de modelo!!!!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for loss_f in (MSELoss, NLPDLoss, MSSSIMLoss):\n",
    "\n",
    "    ae = EntropyLimitedAutoencoder()\n",
    "    criterion = loss_f()\n",
    "    optimizer = optim.AdamW(ae.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:  # dataloader ya tiene los batches de 64x1x256x256\n",
    "            batch = batch[0] # Extraer tensor\n",
    "\n",
    "            optimizer.zero_grad()  # Reiniciar gradientes\n",
    "\n",
    "            outputs = ae(batch)  # Forward pass\n",
    "            loss = criterion(outputs, batch)  # Comparar con entrada\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Actualizar pesos\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Pérdida: {loss.item():.6f}\")\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Época [{epoch+1}/{num_epochs}], Pérdida: {avg_loss:.6f}\")\n",
    "        \n",
    "    print(\"Cambiando de modelo!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = LoadNoise(limit = 30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida: 0.093396\n",
      "Pérdida: 0.138100\n",
      "Pérdida: 0.104613\n",
      "Pérdida: 0.091410\n",
      "Pérdida: 0.091661\n",
      "Pérdida: 0.092229\n",
      "Pérdida: 0.089505\n",
      "Pérdida: 0.087276\n",
      "Época [1/3], Pérdida: 0.098524\n",
      "Pérdida: 0.085568\n",
      "Pérdida: 0.084921\n",
      "Pérdida: 0.084390\n",
      "Pérdida: 0.084634\n",
      "Pérdida: 0.085227\n",
      "Pérdida: 0.084838\n",
      "Pérdida: 0.084182\n",
      "Pérdida: 0.083132\n",
      "Época [2/3], Pérdida: 0.084612\n",
      "Pérdida: 0.082474\n",
      "Pérdida: 0.082575\n",
      "Pérdida: 0.082751\n",
      "Pérdida: 0.082880\n",
      "Pérdida: 0.082611\n",
      "Pérdida: 0.082121\n",
      "Pérdida: 0.081613\n",
      "Pérdida: 0.081174\n",
      "Época [3/3], Pérdida: 0.082275\n",
      "Cambiando de modelo!!!!\n",
      "Pérdida: 569.999573\n",
      "Pérdida: 721.358887\n",
      "Pérdida: 613.346985\n",
      "Pérdida: 588.764832\n",
      "Pérdida: 570.333862\n",
      "Pérdida: 562.290894\n",
      "Pérdida: 555.920715\n",
      "Pérdida: 171.331589\n",
      "Época [1/3], Pérdida: 544.168417\n",
      "Pérdida: 541.991577\n",
      "Pérdida: 541.422180\n",
      "Pérdida: 539.005188\n",
      "Pérdida: 532.587036\n",
      "Pérdida: 525.365723\n",
      "Pérdida: 514.876343\n",
      "Pérdida: 510.431152\n",
      "Pérdida: 157.662247\n",
      "Época [2/3], Pérdida: 482.917681\n",
      "Pérdida: 489.874603\n",
      "Pérdida: 483.766937\n",
      "Pérdida: 475.216125\n",
      "Pérdida: 471.361023\n",
      "Pérdida: 463.233063\n",
      "Pérdida: 459.304474\n",
      "Pérdida: 453.682770\n",
      "Pérdida: 140.441895\n",
      "Época [3/3], Pérdida: 429.610111\n",
      "Cambiando de modelo!!!!\n",
      "Pérdida: 0.852739\n",
      "Pérdida: 0.822483\n",
      "Pérdida: 0.790336\n",
      "Pérdida: 0.725521\n",
      "Pérdida: 0.666720\n",
      "Pérdida: 0.623994\n",
      "Pérdida: 0.552366\n",
      "Pérdida: 0.522007\n",
      "Época [1/3], Pérdida: 0.694521\n",
      "Pérdida: 0.454503\n",
      "Pérdida: 0.427445\n",
      "Pérdida: 0.415308\n",
      "Pérdida: 0.392988\n",
      "Pérdida: 0.381004\n",
      "Pérdida: 0.366034\n",
      "Pérdida: 0.354360\n",
      "Pérdida: 0.343691\n",
      "Época [2/3], Pérdida: 0.391917\n",
      "Pérdida: 0.321889\n",
      "Pérdida: 0.313802\n",
      "Pérdida: 0.305581\n",
      "Pérdida: 0.299058\n",
      "Pérdida: 0.292335\n",
      "Pérdida: 0.288998\n",
      "Pérdida: 0.282744\n",
      "Pérdida: 0.274730\n",
      "Época [3/3], Pérdida: 0.297392\n",
      "Cambiando de modelo!!!!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for loss_f in (MSELoss, NLPDLoss, MSSSIMLoss):\n",
    "\n",
    "    ae = EntropyLimitedAutoencoder()\n",
    "    criterion = loss_f()\n",
    "    optimizer = optim.AdamW(ae.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in noise:  # dataloader ya tiene los batches de 64x1x256x256\n",
    "            batch = batch[0] # Extraer tensor\n",
    "\n",
    "            optimizer.zero_grad()  # Reiniciar gradientes\n",
    "\n",
    "            outputs = ae(batch)  # Forward pass\n",
    "            loss = criterion(outputs, batch)  # Comparar con entrada\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Actualizar pesos\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Pérdida: {loss.item():.6f}\")\n",
    "        avg_loss = total_loss / len(noise)\n",
    "        print(f\"Época [{epoch+1}/{num_epochs}], Pérdida: {avg_loss:.6f}\")\n",
    "        \n",
    "    print(\"Cambiando de modelo!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
